{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUA5qYULS5c7",
        "outputId": "00e28c9b-891c-4f26-9a60-3dfa2e15a140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "# installs\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UOHmfvXjTNFW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many words will generate to the out file for first sequence of words\n",
        "# the first sequence is how the final sequence of words is created, blending\n",
        "# using NLP to make new words\n",
        "# based off how kids will babble over and over again from real words with noises\n",
        "# to make a new word\n",
        "num_words_to_gen = 20"
      ],
      "metadata": {
        "id": "HnGoz64VTyxJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate words based off the alphabet. most results sound like tech companies names\n",
        "# so it has to be massaged down later on\n",
        "def generate_new_words_blend(model_name='gpt2', randomness_factor=0.2, num_words=20):\n",
        "    # Load pre-trained GPT-2 model and tokenizer\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    generated_words = []\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        # Seed with a random string\n",
        "        seed_text = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=5))\n",
        "\n",
        "        # Tokenize the seed text\n",
        "        input_ids = tokenizer.encode(seed_text, return_tensors='pt')\n",
        "\n",
        "        # Generate new words with a blend of randomness\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=15,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=2,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=randomness_factor\n",
        "        )\n",
        "\n",
        "        # Decode and append the generated word to the list\n",
        "        generated_word = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        generated_words.append(generated_word)\n",
        "\n",
        "    return generated_words\n",
        "\n",
        "# Example usage\n",
        "new_words_blend = generate_new_words_blend(randomness_factor=0.5, num_words=num_words_to_gen)\n",
        "print(\"Blended New Words:\", new_words_blend)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsaX5PYdT5Ic",
        "outputId": "f1c606d8-d0cb-4181-c4d3-ef8945185af1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blended New Words: ['sgsoj/\\n\\nThe following is a list of the most popular', 'ibvje, a former member of the European Parliament, said: \"', 'xpqjkq9q7q8q6q5q', 'gqpuz.com/\\n\\nThe following is a list of', 'vkvar.com/en/latest/\\n\\nThe following is', 'cfrwrqjq9q8q7q6q5', 'tljmy.com/\\n\\nThe following is a list of the', 'xihjc.com/\\n\\nThe following is a list of the', 'qlmdm.js\\n\\nThe following code snippet will create a new', 'uccubus, a small, white, black, and white striped fish', 'vxwheezy.com/\\n\\nhttp://www.facebook', 'xqqzpqqzqxqyqwqj', 'djvlh.com/\\n\\nhttp://www.youtube.co', 'irslc.com/\\n\\nThe following is a list of the', 'fckak.com/\\n\\nThe following is a list of the', 'hifuq.com/en/news/local/article/', 'ajbwp.com/wp-content/uploads/2016/03', 'acnfb.com/\\n\\nThe following is a list of the', 'mflsl.com/\\n\\nThe following is a list of the', 'invimator.\\n\\nThe following is a list of the most common']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def take_first_five(string_to_be_cut):\n",
        "  first_five_characters = string_to_be_cut[:5]\n",
        "  return first_five_characters"
      ],
      "metadata": {
        "id": "xQUSDJnsT7KS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the first five characters that resemble a parts of wor\n",
        "thing_1 = take_first_five(new_words_blend[0])\n",
        "print(thing_1)\n",
        "\n",
        "front_new_blend = []\n",
        "for word in new_words_blend:\n",
        "  front_new_blend.append(take_first_five(word))\n",
        "\n",
        "print(front_new_blend)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmQoeMCxT8ij",
        "outputId": "1ebbd8b9-4857-4ccb-aebb-f3dac3abd8af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sgsoj\n",
            "['sgsoj', 'ibvje', 'xpqjk', 'gqpuz', 'vkvar', 'cfrwr', 'tljmy', 'xihjc', 'qlmdm', 'uccub', 'vxwhe', 'xqqzp', 'djvlh', 'irslc', 'fckak', 'hifuq', 'ajbwp', 'acnfb', 'mflsl', 'invim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join two random lines of file\n",
        "def combine_random_lines(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Ensure there are at least two lines in the file\n",
        "    if len(lines) < 2:\n",
        "        return \"Not enough lines in the file to combine.\"\n",
        "\n",
        "    # Choose two random indices\n",
        "    index1, index2 = random.sample(range(len(lines)), 2)\n",
        "\n",
        "    # Combine the selected lines\n",
        "    combined_line = lines[index1].strip() + lines[index2].strip()\n",
        "\n",
        "    if (len(combined_line) >= 13):\n",
        "      #print(\"too long\")\n",
        "      combine_random_lines(file_path)\n",
        "      return combined_line\n",
        "    else:\n",
        "      #print(\"returning new word: \" + combined_line)\n",
        "      return combined_line\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/words.txt'  # Replace with your file path\n",
        "result = combine_random_lines(file_path)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHxwBFPMT-WU",
        "outputId": "067a6740-1ed9-4129-a669-65553d7819dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formlesslyoverstimulates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/words.txt'  # Replace with your file path\n",
        "\n",
        "list_smashed_words = []\n",
        "\n",
        "for i in range(num_words_to_gen):\n",
        "    result = combine_random_lines(file_path)\n",
        "    #print(\"appending new word: \" + result)\n",
        "    list_smashed_words.append(result)\n",
        "\n",
        "print(list_smashed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJKcAz6fT_8U",
        "outputId": "246403a3-71e1-4ece-9bc8-a2520d5e888b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nonpungencyunoperating', 'unreproachableabbreviation', 'stoppleterpenic', 'scaenaplagula', 'backbonedjadery', 'harkenPantagruelically', 'pharmacophobiagalabiya', 'slap-sidedundenunciatory', 'elutiondouble-face', 'voidlymycetomas', 'unemotionedseparates', 'perfectadutra', 'scryvileyns', 'Bladenboroprequarantine', 'interconnectednesssantoninic', 'masquerbeavery', 'IyarApaturia', 'twice-sufficientunblemishing', 'rowdyvapor-headed', 'momentallyserviceably']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get 2-5 chars\n",
        "\n",
        "def get_random_two_five_line(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        # Read lines from the file\n",
        "        lines = file.readlines()\n",
        "\n",
        "        # Filter lines with lengths between 2 and 5 characters\n",
        "        filtered_lines = [line.strip() for line in lines if 2 <= len(line.strip()) <= 5]\n",
        "\n",
        "        # Check if there are eligible lines\n",
        "        if not filtered_lines:\n",
        "            return \"No lines with lengths between 2 and 5 characters found.\"\n",
        "\n",
        "        # Choose a random line from the filtered ones\n",
        "        random_line = random.choice(filtered_lines)\n",
        "\n",
        "    return random_line\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/words.txt'  # Replace with your file path\n",
        "result = get_random_two_five_line(file_path)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83_ooC0NUBpP",
        "outputId": "8da8010c-ec1e-4523-9d46-a4c9b85f41ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tupi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_two_five_list = []\n",
        "for i in range(20):\n",
        "  file_path = '/content/drive/MyDrive/Colab Notebooks/words.txt'  # Replace with your file path\n",
        "  result = get_random_two_five_line(file_path)\n",
        "  random_two_five_list.append(result)"
      ],
      "metadata": {
        "id": "4uBKTw84UDFv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_two_five_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWSadUN0UEQS",
        "outputId": "0dadb3b5-6b81-42d4-e015-283696f320af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EDTCC', 'abaze', 'sprue', 'pinas', 'Bukum', 'baff', 'gavot', 'IPC', 'GTSI', 'Yuki', 'Vlad', 'couve', 'sumi', 'Nepa', 'drunt', 'winks', 'neral', 'diced', 'bl.', 'yourn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(front_new_blend)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSMrATY1UFSi",
        "outputId": "54edf1ae-3016-4ec5-f3f3-af85a6ff4111"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sgsoj', 'ibvje', 'xpqjk', 'gqpuz', 'vkvar', 'cfrwr', 'tljmy', 'xihjc', 'qlmdm', 'uccub', 'vxwhe', 'xqqzp', 'djvlh', 'irslc', 'fckak', 'hifuq', 'ajbwp', 'acnfb', 'mflsl', 'invim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_equal_amount(original, replacement):\n",
        "    # Choose a random starting index for replacement\n",
        "    start_index = random.randint(0, len(original) - len(replacement))\n",
        "\n",
        "    # Perform the replacement\n",
        "    modified = original[:start_index] + replacement + original[start_index + len(replacement):]\n",
        "\n",
        "    return modified\n",
        "\n",
        "# pull this string from list_smashed_words\n",
        "original_string = \"unteaminheritable\"\n",
        "replacement_string = \"quey\"\n",
        "\n",
        "result = replace_equal_amount(original_string, replacement_string)\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qobXSvEmUGhk",
        "outputId": "e9650f5a-f79d-448c-e1c4-d85ffe03e711"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uqueyminheritable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of random_two_five_list\", len(random_two_five_list))\n",
        "print(\"Length of front_new_blend\", len(front_new_blend))\n",
        "print(\"Length of list_smashed_words\", len(list_smashed_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEtzUXqJUH9A",
        "outputId": "1ca36889-54b7-4f4c-bd78-47646aca4275"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of random_two_five_list 20\n",
            "Length of front_new_blend 20\n",
            "Length of list_smashed_words 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_smashed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4tPQ17_UJBj",
        "outputId": "b4c6d492-0bf3-4579-fdbf-95406370a229"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nonpungencyunoperating', 'unreproachableabbreviation', 'stoppleterpenic', 'scaenaplagula', 'backbonedjadery', 'harkenPantagruelically', 'pharmacophobiagalabiya', 'slap-sidedundenunciatory', 'elutiondouble-face', 'voidlymycetomas', 'unemotionedseparates', 'perfectadutra', 'scryvileyns', 'Bladenboroprequarantine', 'interconnectednesssantoninic', 'masquerbeavery', 'IyarApaturia', 'twice-sufficientunblemishing', 'rowdyvapor-headed', 'momentallyserviceably']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_list_equal_amount(list1, list2):\n",
        "  list_ret = []\n",
        "  for item1, item2 in zip(list1, list2):\n",
        "    #print(item1, item2)\n",
        "    #original_string = \"unteaminheritable\"\n",
        "    #replacement_string = \"quey\"\n",
        "\n",
        "    result = replace_equal_amount(item2, item1)\n",
        "    list_ret.append(result)\n",
        "    print(result)\n",
        "\n",
        "  return list_ret"
      ],
      "metadata": {
        "id": "ZUZ5ShddUKX8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_thin = replace_list_equal_amount(random_two_five_list, list_smashed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egS67GkaULvr",
        "outputId": "3f949684-8e95-4e45-e786-700faee74a40"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nonpuEDTCCyunoperating\n",
            "unreproachabazebbreviation\n",
            "stosprueerpenic\n",
            "scaenappinasa\n",
            "backboneBukumry\n",
            "harkenPabaffruelically\n",
            "pgavotcophobiagalabiya\n",
            "slapIPCdedundenunciatory\n",
            "GTSIiondouble-face\n",
            "voidYukicetomas\n",
            "unemotiVladseparates\n",
            "perfecouvetra\n",
            "sumivileyns\n",
            "BladenboropreqNepantine\n",
            "interdruntctednesssantoninic\n",
            "mwinksrbeavery\n",
            "IyarAneralia\n",
            "twice-sufficientunblemdicedg\n",
            "rowbl.apor-headed\n",
            "momentallyseryournbly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_random_chars(input_string, len_to_remove):\n",
        "    if len(input_string) < len_to_remove:\n",
        "        return \"String is too short to remove 4 consecutive characters.\"\n",
        "\n",
        "    start_index = random.randint(0, len(input_string) - len_to_remove)\n",
        "    modified_string = input_string[:start_index] + input_string[start_index + len_to_remove:]\n",
        "\n",
        "    return modified_string\n",
        "\n",
        "# Example usage\n",
        "original_string = full_thin[0]\n",
        "result = remove_random_chars(original_string, 17)\n",
        "\n",
        "print(\"Original string:\", original_string)\n",
        "print(\"Modified string:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc1tQ13hUM9y",
        "outputId": "cf7f8140-95e9-429e-c2f7-225c70b3946e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string: nonpuEDTCCyunoperating\n",
            "Modified string: nting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next\n",
        "# go through list and remove characters for each diff length and good output\n",
        "final_day_list = []\n",
        "spot_in_list = 0"
      ],
      "metadata": {
        "id": "x_VvvM0XUORY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this block and block below need to run back and forth\n",
        "original_string = full_thin[spot_in_list]\n",
        "final_word_result = remove_random_chars(original_string, 7)\n",
        "\n",
        "print(\"Original string:\", original_string)\n",
        "print(\"Modified string:\", final_word_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVxCeDHHUPck",
        "outputId": "980b1f36-ba2c-4904-d31f-31f73f213075"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string: nonpuEDTCCyunoperating\n",
            "Modified string: nonyunoperating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_day_list.append(final_word_result)\n",
        "spot_in_list = spot_in_list + 1\n",
        "print(final_day_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lt82YN-UQkx",
        "outputId": "924952ae-ea4a-4f01-8754-034701a7facd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nonyunoperating']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = final_day_list\n",
        "content = input(\"Enter the name of the file: \")\n",
        "\n",
        "# Specify the file path\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/\" + content + \".txt\"\n",
        "print(file_path)\n",
        "\n",
        "# Open the file in write mode ('w')\n",
        "with open(file_path, 'w') as file:\n",
        "    # Write each item in the list to a new line in the file\n",
        "    for item in my_list:\n",
        "        file.write(\"%s\\n\" % item)\n",
        "\n",
        "print(f\"The list has been written to {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzFQTuFxURrB",
        "outputId": "de71800d-2f66-466a-acbd-d3ca8013a7ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name of the file: fluff-remove-2\n",
            "/content/drive/MyDrive/Colab Notebooks/fluff-remove-2.txt\n",
            "The list has been written to /content/drive/MyDrive/Colab Notebooks/fluff-remove-2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where the RNN creates the new words off the blended/smashed words"
      ],
      "metadata": {
        "id": "t3TxcikJW-uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import words\n",
        "# Read the file, remove newline characters, and create a list of lines\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/words-week-one.txt'\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    lines = [line.strip() for line in file]\n",
        "\n",
        "# Print the list of lines\n",
        "print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGibmRaxXEAm",
        "outputId": "f3ac5abe-562b-42b4-dd0b-e858f6edbbe4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['semitropist', 'unimbezSi', 'lawnle', 'needlemahip', 'telotist', 'Combeies', 'unfixatedrpst', 'unfingeress', 'charaSupeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a dataset of input-output pairs\n",
        "def generate_dataset(words, sequence_length=3):\n",
        "    X, y = [], []\n",
        "    for word in words:\n",
        "        for i in range(len(word) - sequence_length):\n",
        "            sequence_in = word[i : i + sequence_length]\n",
        "            sequence_out = word[i + sequence_length]\n",
        "            X.append([char_to_int[char] for char in sequence_in])\n",
        "            y.append(char_to_int[sequence_out])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# List of existing words\n",
        "existing_words = lines\n",
        "\n",
        "# Create a set of unique characters\n",
        "chars = sorted(set(\"\".join(existing_words)))\n",
        "char_to_int = {char: i for i, char in enumerate(chars)}\n",
        "int_to_char = {i: char for i, char in enumerate(chars)}\n",
        "\n",
        "# Hyperparameters\n",
        "sequence_length = 3\n",
        "n_chars = len(chars)\n",
        "n_units = 128\n",
        "\n",
        "# Generate the dataset\n",
        "X, y = generate_dataset(existing_words, sequence_length)\n",
        "\n",
        "\n",
        "# Reshape the input data for LSTM (samples, time steps, features)\n",
        "X = np.reshape(X, (X.shape[0], sequence_length, 1))"
      ],
      "metadata": {
        "id": "ELnekKIeXMWw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_units, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(n_chars, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "4zdYzwTJXOV9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=1, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq8POFX1XP_O",
        "outputId": "ba375592-9963-4a1d-d061-316cc5fa5949"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "60/60 - 2s - loss: 3.0810 - 2s/epoch - 35ms/step\n",
            "Epoch 2/100\n",
            "60/60 - 0s - loss: 2.7959 - 235ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "60/60 - 0s - loss: 2.7560 - 214ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "60/60 - 0s - loss: 2.7172 - 217ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "60/60 - 0s - loss: 2.6984 - 213ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "60/60 - 0s - loss: 2.6706 - 227ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "60/60 - 0s - loss: 2.6572 - 216ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "60/60 - 0s - loss: 2.6297 - 189ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "60/60 - 0s - loss: 2.6080 - 191ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "60/60 - 0s - loss: 2.5817 - 204ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "60/60 - 0s - loss: 2.5468 - 234ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "60/60 - 0s - loss: 2.5165 - 199ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "60/60 - 0s - loss: 2.4723 - 193ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "60/60 - 0s - loss: 2.4260 - 196ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "60/60 - 0s - loss: 2.3912 - 214ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "60/60 - 0s - loss: 2.3669 - 241ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "60/60 - 0s - loss: 2.3184 - 209ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "60/60 - 0s - loss: 2.3031 - 231ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "60/60 - 0s - loss: 2.2390 - 201ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "60/60 - 0s - loss: 2.1925 - 229ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "60/60 - 0s - loss: 2.1717 - 227ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "60/60 - 0s - loss: 2.1192 - 222ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "60/60 - 0s - loss: 2.0886 - 198ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "60/60 - 0s - loss: 2.0295 - 223ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "60/60 - 0s - loss: 2.0012 - 226ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "60/60 - 0s - loss: 1.9804 - 211ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "60/60 - 0s - loss: 1.9160 - 204ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "60/60 - 0s - loss: 1.8548 - 308ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "60/60 - 0s - loss: 1.8231 - 353ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "60/60 - 0s - loss: 1.7755 - 345ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "60/60 - 0s - loss: 1.7522 - 369ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "60/60 - 0s - loss: 1.7038 - 366ms/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "60/60 - 0s - loss: 1.6135 - 375ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "60/60 - 0s - loss: 1.5572 - 356ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "60/60 - 0s - loss: 1.5598 - 353ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "60/60 - 0s - loss: 1.4860 - 361ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "60/60 - 0s - loss: 1.4422 - 359ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "60/60 - 0s - loss: 1.3875 - 359ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "60/60 - 0s - loss: 1.3533 - 349ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "60/60 - 0s - loss: 1.2921 - 357ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "60/60 - 0s - loss: 1.2706 - 391ms/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "60/60 - 0s - loss: 1.2232 - 366ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "60/60 - 0s - loss: 1.1730 - 446ms/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "60/60 - 1s - loss: 1.1398 - 800ms/epoch - 13ms/step\n",
            "Epoch 45/100\n",
            "60/60 - 1s - loss: 1.1414 - 589ms/epoch - 10ms/step\n",
            "Epoch 46/100\n",
            "60/60 - 0s - loss: 1.0537 - 366ms/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "60/60 - 0s - loss: 1.0538 - 360ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "60/60 - 0s - loss: 0.9984 - 362ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "60/60 - 0s - loss: 0.9828 - 323ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "60/60 - 0s - loss: 0.9222 - 366ms/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "60/60 - 0s - loss: 0.9678 - 389ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "60/60 - 0s - loss: 0.8684 - 309ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "60/60 - 0s - loss: 0.8369 - 355ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "60/60 - 0s - loss: 0.8486 - 334ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "60/60 - 0s - loss: 0.8054 - 328ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "60/60 - 0s - loss: 0.7837 - 358ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "60/60 - 0s - loss: 0.7542 - 344ms/epoch - 6ms/step\n",
            "Epoch 58/100\n",
            "60/60 - 0s - loss: 0.7226 - 323ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "60/60 - 0s - loss: 0.7216 - 326ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "60/60 - 0s - loss: 0.6986 - 307ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "60/60 - 0s - loss: 0.6580 - 306ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "60/60 - 0s - loss: 0.6605 - 334ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "60/60 - 0s - loss: 0.6392 - 342ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "60/60 - 0s - loss: 0.6329 - 304ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "60/60 - 0s - loss: 0.5973 - 321ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "60/60 - 0s - loss: 0.5709 - 329ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "60/60 - 0s - loss: 0.5610 - 320ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "60/60 - 0s - loss: 0.5681 - 407ms/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "60/60 - 0s - loss: 0.5203 - 358ms/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "60/60 - 0s - loss: 0.5071 - 358ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "60/60 - 0s - loss: 0.5201 - 392ms/epoch - 7ms/step\n",
            "Epoch 72/100\n",
            "60/60 - 0s - loss: 0.5225 - 311ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "60/60 - 0s - loss: 0.5008 - 366ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "60/60 - 0s - loss: 0.4779 - 481ms/epoch - 8ms/step\n",
            "Epoch 75/100\n",
            "60/60 - 1s - loss: 0.4404 - 591ms/epoch - 10ms/step\n",
            "Epoch 76/100\n",
            "60/60 - 0s - loss: 0.4470 - 472ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "60/60 - 0s - loss: 0.4442 - 356ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "60/60 - 0s - loss: 0.4126 - 383ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "60/60 - 0s - loss: 0.3997 - 351ms/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "60/60 - 0s - loss: 0.3999 - 337ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "60/60 - 0s - loss: 0.3940 - 344ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "60/60 - 0s - loss: 0.3628 - 340ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "60/60 - 0s - loss: 0.3791 - 336ms/epoch - 6ms/step\n",
            "Epoch 84/100\n",
            "60/60 - 0s - loss: 0.3726 - 333ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "60/60 - 0s - loss: 0.3557 - 323ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "60/60 - 0s - loss: 0.3487 - 341ms/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "60/60 - 0s - loss: 0.3447 - 362ms/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "60/60 - 0s - loss: 0.3268 - 338ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "60/60 - 0s - loss: 0.3293 - 327ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "60/60 - 0s - loss: 0.3127 - 342ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "60/60 - 0s - loss: 0.3239 - 348ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "60/60 - 0s - loss: 0.3306 - 227ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "60/60 - 0s - loss: 0.2998 - 189ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "60/60 - 0s - loss: 0.3075 - 220ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "60/60 - 0s - loss: 0.2702 - 212ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "60/60 - 0s - loss: 0.2908 - 212ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "60/60 - 0s - loss: 0.2990 - 203ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "60/60 - 0s - loss: 0.2744 - 208ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "60/60 - 0s - loss: 0.2782 - 215ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "60/60 - 0s - loss: 0.2688 - 231ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae2da16a020>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a new word using the trained model\n",
        "def gen_word(length=5):\n",
        "  start = np.random.randint(0, len(X)-1)\n",
        "  pattern = np.array(X[start])\n",
        "  result = []\n",
        "\n",
        "\n",
        "  for i in range(length):  # Generating a word with 5 characters\n",
        "      x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "      prediction = model.predict(x, verbose=0)\n",
        "      index = np.argmax(prediction)\n",
        "      result.append(int_to_char[index])\n",
        "      pattern = np.append(pattern, index)[1:]\n",
        "\n",
        "  generated_word = \"\".join(result)\n",
        "  #print(generated_word)\n",
        "  return generated_word"
      ],
      "metadata": {
        "id": "p_huzICxXSGc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_word_list(num_words=20, min_len=3, max_len=22):\n",
        "  ret_list = []\n",
        "  for word in range(num_words):\n",
        "\n",
        "    # Generate a random integer in the specified range\n",
        "    random_integer = random.randint(min_len, max_len)\n",
        "    new_word = gen_word(random_integer)\n",
        "    ret_list.append(new_word)\n",
        "\n",
        "  return ret_list"
      ],
      "metadata": {
        "id": "9iv_vtMvXToo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_word_list = []"
      ],
      "metadata": {
        "id": "g2gUkKBWXU8Q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_word_list = gen_word_list(15, 5, 16)\n",
        "print(new_word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfcZJedqXWT-",
        "outputId": "ca7d69e4-82e7-49fe-cc0d-00d0b6436890"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tostistostis', 'istostisto', 'saiipropistosti', 'geressst', 'atedrpsttttt', 'ipropistostisto', 'ahipropistostis', 'stostistostisto', 'ssstt', 'itropistos', 'pegigeressst', 'tttttttttttttttt', 'esaiipropisto', 'ssstttttt', 'tropisto']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to iterate over the list and ask to remove or keep each item\n",
        "def iteratively_remove_items(my_list):\n",
        "    print(\"Current list:\", my_list)\n",
        "\n",
        "    for item in my_list.copy():  # Create a copy to iterate over while modifying the original\n",
        "        decision = input(f\"Do you want to keep or remove '{item}'? Type 'keep(k)' or 'remove(r)': \").strip().lower()\n",
        "\n",
        "        if decision == 'r':\n",
        "            my_list.remove(item)\n",
        "            print(f\"{item} removed from the list.\")\n",
        "        elif decision != 'k':\n",
        "            print(\"Invalid choice. Item will be kept.\")\n",
        "\n",
        "    print(\"Final list:\", my_list)"
      ],
      "metadata": {
        "id": "tO_1wy-TXX4n"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iteratively_remove_items(new_word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsl45P7bXZZB",
        "outputId": "e29b3e59-0772-448f-fadd-2cd6e14e8810"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current list: ['tostistostis', 'istostisto', 'saiipropistosti', 'geressst', 'atedrpsttttt', 'ipropistostisto', 'ahipropistostis', 'stostistostisto', 'ssstt', 'itropistos', 'pegigeressst', 'tttttttttttttttt', 'esaiipropisto', 'ssstttttt', 'tropisto']\n",
            "Do you want to keep or remove 'tostistostis'? Type 'keep(k)' or 'remove(r)': k\n",
            "Do you want to keep or remove 'istostisto'? Type 'keep(k)' or 'remove(r)': r\n",
            "istostisto removed from the list.\n",
            "Do you want to keep or remove 'saiipropistosti'? Type 'keep(k)' or 'remove(r)': r\n",
            "saiipropistosti removed from the list.\n",
            "Do you want to keep or remove 'geressst'? Type 'keep(k)' or 'remove(r)': r\n",
            "geressst removed from the list.\n",
            "Do you want to keep or remove 'atedrpsttttt'? Type 'keep(k)' or 'remove(r)': r\n",
            "atedrpsttttt removed from the list.\n",
            "Do you want to keep or remove 'ipropistostisto'? Type 'keep(k)' or 'remove(r)': r\n",
            "ipropistostisto removed from the list.\n",
            "Do you want to keep or remove 'ahipropistostis'? Type 'keep(k)' or 'remove(r)': k\n",
            "Do you want to keep or remove 'stostistostisto'? Type 'keep(k)' or 'remove(r)': r\n",
            "stostistostisto removed from the list.\n",
            "Do you want to keep or remove 'ssstt'? Type 'keep(k)' or 'remove(r)': r\n",
            "ssstt removed from the list.\n",
            "Do you want to keep or remove 'itropistos'? Type 'keep(k)' or 'remove(r)': k\n",
            "Do you want to keep or remove 'pegigeressst'? Type 'keep(k)' or 'remove(r)': r\n",
            "pegigeressst removed from the list.\n",
            "Do you want to keep or remove 'tttttttttttttttt'? Type 'keep(k)' or 'remove(r)': r\n",
            "tttttttttttttttt removed from the list.\n",
            "Do you want to keep or remove 'esaiipropisto'? Type 'keep(k)' or 'remove(r)': r\n",
            "esaiipropisto removed from the list.\n",
            "Do you want to keep or remove 'ssstttttt'? Type 'keep(k)' or 'remove(r)': r\n",
            "ssstttttt removed from the list.\n",
            "Do you want to keep or remove 'tropisto'? Type 'keep(k)' or 'remove(r)': k\n",
            "Final list: ['tostistostis', 'ahipropistostis', 'itropistos', 'tropisto']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = new_word_list\n",
        "content = input(\"Enter the name of the file: \")\n",
        "\n",
        "# Specify the file path\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/\" + content + \".txt\"\n",
        "print(file_path)\n",
        "\n",
        "# Open the file in write mode ('w')\n",
        "with open(file_path, 'w') as file:\n",
        "    # Write each item in the list to a new line in the file\n",
        "    for item in my_list:\n",
        "        file.write(\"%s\\n\" % item)\n",
        "\n",
        "print(f\"The list has been written to {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4SCOe59Xbaj",
        "outputId": "a5ea3103-3002-4837-b6d9-ca7fdc1791ec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name of the file: week-two-short\n",
            "/content/drive/MyDrive/Colab Notebooks/week-two-short.txt\n",
            "The list has been written to /content/drive/MyDrive/Colab Notebooks/week-two-short.txt\n"
          ]
        }
      ]
    }
  ]
}